from ultralytics import YOLO
import cv2
from huggingface_hub import hf_hub_download
from ultralytics import YOLO
import cv2
from insightface.app import FaceAnalysis
import cv2, numpy as np, pathlib, pickle, os

# ç›´æ¥å¾ Hugging Face å–æ¬Šé‡
weight = hf_hub_download("arnabdhar/YOLOv8-Face-Detection", "model.pt")


model = YOLO(weight)      # åªæœƒè¼¸å‡ºä¸€å€‹é¡åˆ¥ï¼šface

# --- åƒæ•¸ ---
DB_DIR = "faces_db"          # å·²çŸ¥äººå“¡ç…§ç‰‡æ ¹ç›®éŒ„ï¼ˆå­è³‡æ–™å¤¾ = äººåï¼‰
OUT_PKL = "face_db.pkl"       # è¼¸å‡ºæª”
# YOLO_WEIGHT = "yolov8n-face.pt"  # YOLO æ¨¡å‹åç¨±æˆ–è·¯å¾‘
CONF = 0.3                   # YOLO ç½®ä¿¡åº¦
MARGIN = 0.4                 # å¤–æ“´æ¯”ä¾‹ï¼ˆé¿å…è£å¤ªç·Šï¼‰

def encode_face(img_bgr, bbox, margin=0.25):
    x1, y1, x2, y2 = bbox
    H, W = img_bgr.shape[:2]

    # 1) åŠ  marginï¼Œä¸¦è£åˆ°ç•«é¢ç¯„åœå…§
    dx, dy = int((x2 - x1) * margin), int((y2 - y1) * margin)
    l = max(x1 - dx, 0)
    t = max(y1 - dy, 0)
    r = min(x2 + dx, W)
    b = min(y2 + dy, H)

    # ---------- ç©ºæ¡†ä¿è­· ----------
    if r - l < 10 or b - t < 10:        # å¹…åº¦å¤ªå°ç›´æ¥è·³é
        return None

    face_crop = img_bgr[t:b, l:r]

    # 2) BGR â†’ RGBï¼Œä¸¦ç¢ºä¿é€£çºŒ + uint8
    rgb = cv2.cvtColor(face_crop, cv2.COLOR_BGR2RGB)
    rgb = np.ascontiguousarray(rgb, dtype=np.uint8)

    # 3) å‘Šè¨´ face_recognition è‡‰åœ¨æ•´å¼µ crop å…§
    loc = [(0, rgb.shape[1], rgb.shape[0], 0)]  # (top, right, bottom, left)
    vecs = fr.face_encodings(rgb, known_face_locations=loc)

    return vecs[0] if vecs else None

# --- è¼‰å…¥æ¨¡å‹ ---
print("â–¶ è¼‰å…¥ YOLOv8-Face èˆ‡ InsightFace æ¨¡å‹â€¦")
face_yolo = YOLO(weight)
face_app = FaceAnalysis(name="buffalo_l", providers=["CPUExecutionProvider"])
face_app.prepare(ctx_id=0)

# --- åŠŸèƒ½ï¼šYOLO åµæ¸¬ + InsightFace å‘é‡ ---
def get_aligned_embedding(img_bgr, conf=CONF, margin=MARGIN):
    embeddings = []
    if img_bgr is None or img_bgr.size == 0:
        return embeddings

    h, w = img_bgr.shape[:2]
    results = face_yolo(img_bgr, conf=conf, verbose=False)[0]

    for box in results.boxes.xyxy:
        x1, y1, x2, y2 = map(int, box)
        dx, dy = int((x2 - x1) * margin), int((y2 - y1) * margin)
        l, t = max(x1 - dx, 0), max(y1 - dy, 0)
        r, b = min(x2 + dx, w), min(y2 + dy, h)

        if r - l < 10 or b - t < 10:
            continue

        face_crop = img_bgr[t:b, l:r]
        face_rgb = cv2.cvtColor(face_crop, cv2.COLOR_BGR2RGB)
        faces = face_app.get(face_rgb)
        if faces:
            emb = faces[0].embedding
            emb = emb / np.linalg.norm(emb)  # å–®ä½åŒ–
            embeddings.append(emb)
    return embeddings
if __name__ == "__main__":
    print(f"â–¶ é–‹å§‹è™•ç†è³‡æ–™å¤¾ '{DB_DIR}' â€¦")
    encodings = []
    for person_dir in pathlib.Path(DB_DIR).iterdir():
        if not person_dir.is_dir():
            continue
        name = person_dir.name
        print(f"--- è™•ç† {name} çš„ç…§ç‰‡ ---")
        vectors = []

        for img_path in person_dir.glob("*.*"):
            if img_path.suffix.lower() not in [".jpg", ".jpeg", ".png", ".bmp"]:
                continue
            img = cv2.imread(str(img_path))
            if img is None:
                print(f"[!] ç„¡æ³•è®€å–ï¼š{img_path}")
                continue
            if img.ndim == 2:
                img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)
            elif img.ndim != 3:
                continue

            vecs = get_aligned_embedding(img)
            vectors.extend(vecs)

        if vectors:
            avg_vec = np.mean(vectors, axis=0)
            encodings.append({"name": name, "vec": avg_vec})

    print(f"âœ” æ”¶é›†å®Œæˆï¼Œå…± {len(encodings)} å€‹äººå“¡å‘é‡")
    try:
        with open(OUT_PKL, "wb") as f:
            pickle.dump(encodings, f)
        print(f"ğŸ“¦ å‘é‡åº«è¼¸å‡ºæˆåŠŸ â†’ {OUT_PKL}")
    except Exception as e:
        print(f"[!] å¯«å…¥å¤±æ•—ï¼š{e}")